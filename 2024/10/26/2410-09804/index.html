<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>北京航空航天大学提出一种多目标黑箱优化框架BlackDAN用于有效的上下文劫持大型语言模型 | 安全汪 AnQuanWang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="MathJax &#x3D; {   tex: {     inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\(&#39;, &#39;\)&#39;]]   } };        动机在当今的技术环境中，大型语言模型（LLMs）被越来越广泛地应用于各种场景中，这使得确保这些模型的安全性成为一项重要任务。近期的研究表明，jail breaking，即利用模型的漏洞绕过安全限制并生成有害输出的行为，给LLMs的完整性和伦理">
<meta property="og:type" content="article">
<meta property="og:title" content="北京航空航天大学提出一种多目标黑箱优化框架BlackDAN用于有效的上下文劫持大型语言模型">
<meta property="og:url" content="http://example.com/2024/10/26/2410-09804/index.html">
<meta property="og:site_name" content="安全汪 AnQuanWang">
<meta property="og:description" content="MathJax &#x3D; {   tex: {     inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\(&#39;, &#39;\)&#39;]]   } };        动机在当今的技术环境中，大型语言模型（LLMs）被越来越广泛地应用于各种场景中，这使得确保这些模型的安全性成为一项重要任务。近期的研究表明，jail breaking，即利用模型的漏洞绕过安全限制并生成有害输出的行为，给LLMs的完整性和伦理">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/86dd646a60d7964fc918243cd8363f393bf9eb7e35dfcac53e04503c1858db7d.jpg">
<meta property="og:image" content="http://example.com/images/75b472784dcfc85dbc1c1ce2e86644be6517ef31c868bfe07722c7123e113eea.jpg">
<meta property="og:image" content="http://example.com/images/bc676f7866705fea3ed5e111eb7e902f0e8471841de1ea9d206237a89e347512.jpg">
<meta property="og:image" content="http://example.com/images/a9cac650a3351f6a1f3ccc21f7a733b50ebc2a549b4f258f0e0e6200e0280fbb.jpg">
<meta property="og:image" content="http://example.com/images/3b3a820dc70d5230ea582bd03e9dc75f2bfa58729453189789f46e457b89ee52.jpg">
<meta property="og:image" content="http://example.com/images/d35ec1d1b4c2bc310dbbf5a22f56e0089c03c3d60b77ffee2d6d05429a5b6013.jpg">
<meta property="og:image" content="http://example.com/images/06ee50de00ed83269f4a7dd8865fafbc89f5149242454d1dc4da16728f8579ca.jpg">
<meta property="og:image" content="http://example.com/images/56377804fc7e6814bb0dd75cb5c45f7f492cafade24144bcc341dd699e1d44fc.jpg">
<meta property="og:image" content="http://example.com/images/06ee50de00ed83269f4a7dd8865fafbc89f5149242454d1dc4da16728f8579ca.jpg">
<meta property="article:published_time" content="2024-10-26T15:28:05.000Z">
<meta property="article:modified_time" content="2024-10-26T15:28:05.616Z">
<meta property="article:author" content="Jun">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/86dd646a60d7964fc918243cd8363f393bf9eb7e35dfcac53e04503c1858db7d.jpg">
  
    <link rel="alternate" href="/atom.xml" title="安全汪 AnQuanWang" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">安全汪 AnQuanWang</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一只每天自动跟踪和解读大模型安全领域论文的汪，所有内容均由AI生成</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2410-09804" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/26/2410-09804/" class="article-date">
  <time class="dt-published" datetime="2024-10-26T15:28:05.000Z" itemprop="datePublished">2024-10-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      北京航空航天大学提出一种多目标黑箱优化框架BlackDAN用于有效的上下文劫持大型语言模型
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\(', '\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>




<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>在当今的技术环境中，大型语言模型（LLMs）被越来越广泛地应用于各种场景中，这使得确保这些模型的安全性成为一项重要任务。近期的研究表明，jail breaking，即利用模型的漏洞绕过安全限制并生成有害输出的行为，给LLMs的完整性和伦理性带来了显著挑战。现有的jail breaking方法主要集中在提高攻击成功率（ASR），却往往忽视了其他重要因素，比如jail breaking响应与查询的相关性及隐蔽性。这样的单一目标关注可能导致的攻击效果不佳，要么是生成的响应文不对题，要么是容易被识别出来。</p>
<p>鉴于此，研究者们意识到，需要更为细致的策略来优化查询提示，特别是通过多目标的方法来同时考虑效率和实用性。除此之外，当前的jail breaking方法也存在明显的局限性。例如，许多方法依赖于模型的内部参数进行优化，而缺乏对模型行为的解释和理解，这使得建立一个可靠的安全边界变得困难。优化过程的透明性与可解释性的不足也给现有技术的有效性和可靠性带来了挑战。 </p>
<p>为了解决上述问题，研究者们提出了BlackDAN，这是一种黑箱多目标可控jail breaking优化框架。BlackDAN的创新之处在于同时优化多个目标，如攻击成功率（ASR）、语义一致性等，不再仅仅关注于提高攻击成功率。这种多目标优化的方式，不但在理论和实际应用中展示了更好的性能，也是实现更高层次的安全性与解释性的关键。</p>
<p>通过这项工作，BlackDAN不仅超越了现有单目标优化的方法，还提出了Rank Boundary Hypothesis，探讨了如何在嵌入空间中更好地区分有害和无害的提示。这意味着研究者能够更有效地识别针对特定有害内容分布的jail breaking提示，从而提高了bypass手段的精确性与可靠性。 </p>
<p>整体而言，BlackDAN的出现为多目标jail breaking优化任务提供了一个新的基准。它的高扩展性也使得用户能够根据不同需求自定义和优先排序多种优化目标，为未来的研究与应用指明了方向。</p>
<p><img src="/images/86dd646a60d7964fc918243cd8363f393bf9eb7e35dfcac53e04503c1858db7d.jpg" alt="动机示意图"></p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在本研究中，作者旨在生成能够最大化目标语言模型生成不安全响应的提示，同时确保生成响应与有害问题之间的语义一致性。这个过程被构建为一个多目标优化问题，采用了NSGA-II（非支配排序遗传算法II）进行优化。</p>
<h3 id="适应度函数"><a href="#适应度函数" class="headerlink" title="适应度函数"></a>适应度函数</h3><p>作者定义了两个连续的适应度函数以指导优化过程：</p>
<ul>
<li><p><strong>不安全标记概率（使用 llama guard 2）</strong>：第一个适应度函数 $f_{1}$ 评估目标模型 $T$ 生成的响应 $R$ 包含不安全内容的概率。此概率由代理模型 llama guard 2 计算，该模型输出特定“不安全标记”的对数概率。</p>
<p><img src="/images/75b472784dcfc85dbc1c1ce2e86644be6517ef31c868bfe07722c7123e113eea.jpg"></p>
<p>对于给定的提示 $P$ 和有害问题 $Q$，生成的响应 $R&#x3D;\mathcal T(P,Q)$ 的不安全标记概率计算为：</p>
<p>$$<br>f_{1}(P,Q)&#x3D;\log P(\mathrm{unsafe~toER}\mid R)<br>$$</p>
</li>
<li><p><strong>语义一致性（使用 all-MiniLM-L6-v2）</strong>：在黑箱攻击的环境下，研究者没有直接访问目标模型内部或其嵌入的能力。因此，作者采用了预训练的代理模型，例如 all-MiniLM-L6-v2，来生成有害提示与候选响应的句子嵌入。这些嵌入允许测量提示和响应之间的语义相似度。</p>
<p>第二个适应度函数 $f_{2}$ 测量生成的响应 $R$ 与有害问题 $Q$ 的语义一致性。通过计算余弦相似度，得到：</p>
<p>$$<br>f_{2}(P,Q)&#x3D;\mathrm{Sim}(\mathbf{e}<em>{Q},\mathbf{e}</em>{R})&#x3D;\frac{\mathbf{e}<em>{Q}\cdot\mathbf{e}</em>{R}}{\left|\mathbf{e}<em>{Q}\right|\left|\mathbf{e}</em>{R}\right|},<br>$$</p>
<p>其中 $\cdot$ 代表点积，$\lVert\mathbf e\rVert$ 是嵌入向量的欧几里得范数。作者选择具有较高相似度分数的响应作为越狱输出，确保所选响应在语义上与有害提示对齐。</p>
</li>
</ul>
<h3 id="NSGA-II进行多目标越狱提示优化"><a href="#NSGA-II进行多目标越狱提示优化" class="headerlink" title="NSGA-II进行多目标越狱提示优化"></a>NSGA-II进行多目标越狱提示优化</h3><p>为了找到最佳的越狱提示集合，作者应用了NSGA-II算法。该算法基于两个关键标准进行多目标优化：</p>
<ul>
<li><p><strong>支配关系</strong>：如果解决方案 $P_{1}$ 在至少一个目标上优于解决方案 $P_{2}$ 且在所有其他目标上不劣于 $P_{2}$，则称 $P_{1}$ 支配 $P_{2}$。其支配关系定义为：</p>
<p>$$<br>\begin{array}{r}{P_{1}\prec P_{2}\quad\mathrm{if}\quad\forall i\in{1,2,\ldots,m},\quad f_{i}(P_{1},Q)\geq f_{i}(P_{2},Q)}\ {\quad\mathrm{and}\quad\exists j\in{1,2,\ldots,m},\quad f_{j}(P_{1},Q)&gt;f_{j}(P_{2},Q),}\end{array}<br>$$</p>
</li>
<li><p><strong>拥挤距离</strong>：一旦种群根据非支配前沿进行排序，就会为每个解决方案分配拥挤距离，以保持多样性。拥挤距离 $d(P)$ 的计算涉及所有 $m$ 个目标函数。对于每个目标 $f_{i}$，拥挤距离的计算如下：</p>
<p>$$<br>d(P)&#x3D;\sum_{i&#x3D;1}^{m}\left(\frac{f_{i}^{\mathrm{ext}}-f_{i}^{\mathrm{prev}}}{f_{i}^{\mathrm{max}}-f_{i}^{\mathrm{min}}}\right)<br>$$</p>
</li>
</ul>
<p>通过这种方式，选择来自每个非支配前沿的解决方案时，不仅考虑多个目标的最优性，也考虑每个目标的多样性。</p>
<h3 id="遗传操作：交叉和变异"><a href="#遗传操作：交叉和变异" class="headerlink" title="遗传操作：交叉和变异"></a>遗传操作：交叉和变异</h3><p>NSGA-II使用遗传操作进化种群：  </p>
<ul>
<li><p><strong>交叉</strong>：该操作通过重新组合两个父代提示生成两个新的后代。设 $P_{1}$ 和 $P_{2}$ 为父代提示。后代 $C_{1}$ 和 $C_{2}$ 是通过随机交换两个父代提示的句子生成的：</p>
<p>$$<br>C_{1},C_{2}&#x3D;\mathrm{Crossover}(P_{1},P_{2}).<br>$$</p>
</li>
<li><p><strong>变异</strong>：变异操作通过用同义词修改提示中的随机选定单词来引入多样性。设 $W$ 为提示 $P$ 中随机选择的单词，$\operatorname{Sym}(W)$ 表示 $W$ 的同义词集合。变异后的提示生成如下：</p>
<p>$$<br>P^{\prime}&#x3D;\mathrm{Mutation}(P)\quad\mathrm{where}\quad W^{\prime}\in\mathrm{Sym}(W).<br>$$</p>
</li>
</ul>
<p>完整的算法提供在附录中的算法 1 和 2，由于空间限制未详述。 </p>
<p>整体上，BlackDAN框架及其方法论为生成有效且可解释的越狱提示提供了一种系统化的方案，同时确保在不断优化的过程中，保持各种目标之间的平衡。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>为了评估针对大型语言模型（LLMs）的监狱破解攻击，研究使用了AdvBench数据集。该数据集包含520个请求，涵盖了多种类别，包括亵渎、图形描绘、威胁行为、虚假信息、歧视、网络犯罪及危险或非法建议等。  </p>
<p>在多模态数据集方面，研究使用了MM-Safety Bench。该数据集涵盖了13种场景，包括非法活动、仇恨言论、身体伤害和健康咨询，总共包含5,040个文本-图像对。  </p>
<p>研究使用了多种最先进的开源大型语言模型（LLMs），包括Llama-2-7b-hf、Llama-2-13b-hf、Internlm2-chat-7b、Vicuna-7b、AquilaChat-7B、Baichuan-7B、Baichuan2-13BChat、GPT-2-XL、Minitron-8B-Base、Yi-1.5-9B-Chat等。对于多模态LLMs，研究还使用了llava-v1.6-mistral-7b-hf和llava-v1.6-vicuna-7b-hf，以展示所提方法在从单模态到多模态能力扩展中的有效性。  </p>
<h3 id="单目标（有害性）破解优化"><a href="#单目标（有害性）破解优化" class="headerlink" title="单目标（有害性）破解优化"></a>单目标（有害性）破解优化</h3><p>下表比较了不同模型在不同条件下的攻击方法（AdvBench 520个样本）。  </p>
<p><img src="/images/bc676f7866705fea3ed5e111eb7e902f0e8471841de1ea9d206237a89e347512.jpg">  </p>
<p>时间效率方面，黑箱方法（“不使用问题”和“使用问题”）相比于白箱方法显著更快，使用问题和响应时平均每个样本处理时间约为2分钟，而白箱方法处理时间约为15分钟，灰箱方法约为12分钟。在Llama2-7b-chat模型中，利用有害问题的“使用问题”方法的成功率显著提高，从白箱的45.3%增加到黑箱的93.1%。  </p>
<p>传递攻击方面，Vicuna-7B-v1.5展示了最高的成功率，从白箱场景的13.7%增加到黑箱场景的99.2%。所有模型（如Vicuna-7B-v1.5）均通过迁移学习从Llama2-7b-chat衍生而来。其他模型也呈现类似趋势，但Llama3-8B在包含有害问题时显示出轻微下降。  </p>
<h3 id="多目标优化"><a href="#多目标优化" class="headerlink" title="多目标优化"></a>多目标优化</h3><p>下图比较了各种模型的单目标黑箱监狱破解攻击的成功率及这些攻击的传递能力。  </p>
<p><img src="/images/a9cac650a3351f6a1f3ccc21f7a733b50ebc2a549b4f258f0e0e6200e0280fbb.jpg">  </p>
<p>最终行展示了多目标自我攻击优化的结果，结果表明其始终优于或与自我攻击相比相当，表明这种方法提供了更强、更具通用性的攻击能力。  </p>
<p>传递成功率因模型而异，某些模型（如GPT-2-XL和Baichuan2-13B-Chat）表现出更高的脆弱性，而Llama-2-7b-hf和Llama-2-13b-hf的抵抗能力更强，基于列均值的评估（不含自我攻击）。  </p>
<p>下图展示了跨不同场景的多模态模型破解。  </p>
<p><img src="/images/3b3a820dc70d5230ea582bd03e9dc75f2bfa58729453189789f46e457b89ee52.jpg">  </p>
<p>结果表明，多目标优化在所有有害类别和情景下都显著优于单目标（SO）方法。多目标（MO）方法在攻击成功率（ASR）上始终取得更高的成绩，llava-v1.6-mistral-7b-hf MO在许多情况下达到了100%的成功率。整体而言，多目标优化在所有模型和条件下均证明其优于单目标方法的效果。  </p>
<h3 id="最佳Pareto等级与最差Pareto等级嵌入比较"><a href="#最佳Pareto等级与最差Pareto等级嵌入比较" class="headerlink" title="最佳Pareto等级与最差Pareto等级嵌入比较"></a>最佳Pareto等级与最差Pareto等级嵌入比较</h3><p>下图比较了使用三种可视化技术（PCA 2D、PCA 3D和UMAP）获得的最佳和最差Pareto等级样本的嵌入。  </p>
<p><img src="/images/d35ec1d1b4c2bc310dbbf5a22f56e0089c03c3d60b77ffee2d6d05429a5b6013.jpg">  </p>
<p>PCA图中，支持向量机（SVM）决策边界有效地区分了两个组别，展现出不同等级占据嵌入空间的不同区域。此外，该UMAP可视化展示了最佳和最差等级的样本的明确和紧凑集群。这些结果强烈表明，Pareto排序不仅能够区分监狱破解提示的质量，还对提示在嵌入空间中的表现具有显著的影响。  </p>
<h3 id="Pareto等级和嵌入空间"><a href="#Pareto等级和嵌入空间" class="headerlink" title="Pareto等级和嵌入空间"></a>Pareto等级和嵌入空间</h3><p>下图展示了跨多个数据集的不同Pareto等级类别之间的关系，通过将嵌入投影到一个二维球面上。  </p>
<p><img src="/images/06ee50de00ed83269f4a7dd8865fafbc89f5149242454d1dc4da16728f8579ca.jpg">  </p>
<p>每个子图代表特定模型，数据点根据Pareto等级进行颜色编码，较大的点表示每个等级的Fréchet均值。Fréchet均值通过绿色测地线连接，展示了均值随着Pareto等级降低而平滑变化的趋势，这表明更好的数据点。在每个Fréchet均值处，应用切线PCA分析数据的局部变异，捕捉围绕每个均值点的主要变化方向。该可视化方法展示了嵌入的全局几何结构和局部变异，为如何通过多目标优化平衡竞争目标及增强文本嵌入的结构提供了新的见解。  </p>
<h3 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h3><p>下表展示了不同模型在ASR和GPT-4 Metric评分上的比较。  </p>
<p><img src="/images/56377804fc7e6814bb0dd75cb5c45f7f492cafade24144bcc341dd699e1d44fc.jpg">  </p>
<p>结果表明，BlackDAN（我们的多目标方法）在所有模型中均表现优异，达到最高的ASR和GPT-4 Metric评分。尤其在Llama2-7b上，ASR达到了95.4%，而在Vicuna-7b上达到了97.5%，相比于传统方法Deep Inception在Llama2-7b上的77.5%和在Vicuna-7b上的92.7%都有了显著提升。GPT-4模型整体上显示出最低的ASR（71.4%），但相较于其他方法，BlackDAN在GPT-4上的表现依然相对稳健。此外，GPT-4 Metric评估的生成输出中的伦理违规程度表明，BlackDAN生成的最有害响应在Llama2-7b和Vicuna-7b上分别达到了93.8和96.0的最高评分，超过了其他技术。  </p>
<h3 id="适应性分析"><a href="#适应性分析" class="headerlink" title="适应性分析"></a>适应性分析</h3><p>下图展示了随着代数增加而收敛的适应性（fitness）结果。  </p>
<p><img src="/images/06ee50de00ed83269f4a7dd8865fafbc89f5149242454d1dc4da16728f8579ca.jpg">  </p>
<p>结果表明，随着代数的增加，适应性评分趋于稳定，指示收敛到一个稳定状态。在这一过程中，依据适应性评价的模型性能显著改善，进一步支持所提方法的有效性。大约在第50代，大多数最先进的（SOTA）大型语言模型（LLMs）达到了收敛，进一步突显了所提方法的效率。  </p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在本文中，研究者们介绍了BlackDAN，这是一种多目标、可控的监狱破解优化框架，适用于大型语言模型（LLMs）和多模态大型语言模型（MLLMs）。BlackDAN的主要创新在于不仅优化攻击成功率（ASR），还关注上下文一致性，确保监狱破解的响应在语义上与原始的有害提示保持一致。这样，不仅确保了响应的隐秘性，还提高了其实用性。</p>
<p>通过利用NSGA-II算法，BlackDAN显著改善了传统单目标技术的效果，在多个模型上实现了更高的成功率和更连贯的监狱破解响应。此外，BlackDAN具有高度的可扩展性，允许集成任意数量的用户定义目标，使其成为一个广泛适用的优化框架。</p>
<p>特别是，BlackDAN将多个目标，包括ASR、隐秘性和语义一致性纳入考虑，这为生成既实用又可解释的监狱破解响应设定了新的基准，同时在评估中保持了安全性和鲁棒性。这些创新为应对大型语言模型在安全性方面的挑战提供了新的思路，展现了多目标优化的优势。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/26/2410-09804/" data-id="cm2qbqgjv00083pjl4bkv38bx" data-title="北京航空航天大学提出一种多目标黑箱优化框架BlackDAN用于有效的上下文劫持大型语言模型" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/10/26/2410-04447/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          印度理工学院鲁尔基分校提出无训练的注意力重加权方法以减少生成模型中的不安全内容
        
      </div>
    </a>
  
  
    <a href="/2024/10/26/2410-09040/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">加州大学圣克鲁斯分校提出了一种基于注意力操控的增强型大语言模型越狱攻击方法</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/26/2410-04447/">印度理工学院鲁尔基分校提出无训练的注意力重加权方法以减少生成模型中的不安全内容</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-09804/">北京航空航天大学提出一种多目标黑箱优化框架BlackDAN用于有效的上下文劫持大型语言模型</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-09040/">加州大学圣克鲁斯分校提出了一种基于注意力操控的增强型大语言模型越狱攻击方法</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-10414/">新加坡国立大学提出的基于大型语言模型的内容审核守护模型的可靠性校准方法</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-11459/">莫纳什大学提出多轮交互的Jigsaw Puzzles策略以破解大型语言模型的安全防护</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Jun<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>