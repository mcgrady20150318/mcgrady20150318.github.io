<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>莫纳什大学提出多轮交互的Jigsaw Puzzles策略以破解大型语言模型的安全防护 | 安全汪 AnQuanWang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="MathJax &#x3D; {   tex: {     inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\(&#39;, &#39;\)&#39;]]   } };        动机大型语言模型（LLMs）的发展使其在与人类互动及处理复杂问题时表现出色。这些模型能够利用其庞大的隐性知识和强大的推理能力，展现出出色的记忆能力和处理多轮对话的能力。然而，随着技术的进步，安全性问题也随之而来。现有的LLMs存在的脆弱性使其">
<meta property="og:type" content="article">
<meta property="og:title" content="莫纳什大学提出多轮交互的Jigsaw Puzzles策略以破解大型语言模型的安全防护">
<meta property="og:url" content="http://example.com/2024/10/26/2410-11459/index.html">
<meta property="og:site_name" content="安全汪 AnQuanWang">
<meta property="og:description" content="MathJax &#x3D; {   tex: {     inlineMath: [[&#39;$&#39;, &#39;$&#39;], [&#39;\(&#39;, &#39;\)&#39;]]   } };        动机大型语言模型（LLMs）的发展使其在与人类互动及处理复杂问题时表现出色。这些模型能够利用其庞大的隐性知识和强大的推理能力，展现出出色的记忆能力和处理多轮对话的能力。然而，随着技术的进步，安全性问题也随之而来。现有的LLMs存在的脆弱性使其">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/97a00d14482146ef83f588af28ce2c9d2832703863cab361d3de578afeb59d40.jpg">
<meta property="og:image" content="http://example.com/images/97a00d14482146ef83f588af28ce2c9d2832703863cab361d3de578afeb59d40.jpg">
<meta property="og:image" content="http://example.com/images/ae7060caac9ca93772c10f1266fff7e01e6859ba334dbe42a0a3396528551659.jpg">
<meta property="og:image" content="http://example.com/images/eacbfddfa907932e856b1a2a6cb7c3f489188b8e10d65e38fb59e1fc167f0ec7.jpg">
<meta property="article:published_time" content="2024-10-26T14:35:39.000Z">
<meta property="article:modified_time" content="2024-10-26T14:35:39.817Z">
<meta property="article:author" content="Jun">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/97a00d14482146ef83f588af28ce2c9d2832703863cab361d3de578afeb59d40.jpg">
  
    <link rel="alternate" href="/atom.xml" title="安全汪 AnQuanWang" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">安全汪 AnQuanWang</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一只每天自动跟踪和解读大模型安全领域论文的汪，所有内容均由AI生成</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2410-11459" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/26/2410-11459/" class="article-date">
  <time class="dt-published" datetime="2024-10-26T14:35:39.000Z" itemprop="datePublished">2024-10-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      莫纳什大学提出多轮交互的Jigsaw Puzzles策略以破解大型语言模型的安全防护
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\(', '\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>




<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>大型语言模型（LLMs）的发展使其在与人类互动及处理复杂问题时表现出色。这些模型能够利用其庞大的隐性知识和强大的推理能力，展现出出色的记忆能力和处理多轮对话的能力。然而，随着技术的进步，安全性问题也随之而来。现有的LLMs存在的脆弱性使其容易受到越狱攻击，从而生成有害的响应。因此，提升LLMs的安全性是迫切需要解决的问题。</p>
<p>近年来，同行评审策略被广泛采用，以测试LLMs的潜在脆弱性，从而促进更强大的防御措施的发展。现有研究主要集中在单轮越狱攻击上，而多轮设置下的脆弱性尚未得到充分探索。为了应对这一挑战，研究者提出了“拼图难题”（Jigsaw Puzzles）这一策略，这是一种简单但有效的多轮越狱攻击方法，通过将有害问题分割成无害部分，在每轮交互中请求LLMs重构并回应完整问题。该研究的实验结果表明，拼图难题能够成功绕过现有防护措施，展现出在多轮交互设置下的显著攻击成功率。</p>
<p>该研究的创新点主要体现在以下几个方面：</p>
<ol>
<li><strong>多轮交互的探索</strong>：该策略专注于对多轮设置下的潜在脆弱性进行探索，填补了当前研究的空白。</li>
<li><strong>拼图策略</strong>：通过将有害问题分拆成无害的部分，来诱使LLMs重构问题并生成响应，从而成功绕过了防护措施。</li>
<li><strong>实验证明</strong>：实验结果显示，在五种先进的LLMs上，拼图难题策略的攻击成功率高达93.76%，展示了其在实际应用中的有效性和广泛适用性。</li>
</ol>
<p>这些创新点不仅揭示了LLMs在面对多轮越狱攻击时的脆弱性，也为未来的安全防护措施的发展提供了可靠的依据和方向。  </p>
<p><img src="/images/97a00d14482146ef83f588af28ce2c9d2832703863cab361d3de578afeb59d40.jpg">  </p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在本研究中，作者提出了一种名为Jigsaw Puzzles（JSP）的策略，用于在多轮交互中对大型语言模型（LLMs）进行监狱破解（jailbreaking）。该方法通过将有害查询分割为无害的片段来规避现有的防御机制。以下是该方法的详细步骤：</p>
<h3 id="JSP-提示"><a href="#JSP-提示" class="headerlink" title="JSP 提示"></a>JSP 提示</h3><p>在多轮交互的第一轮中，JSP提示请求LLMs将后续轮次提供的查询片段拼接起来，并进行回答。提示机制主要基于两个策略以确保破解成功：</p>
<ul>
<li><p><strong>禁止生成连接的查询</strong>：现有的LLMs通常依赖识别查询中的明显有害内容来激活它们的防御协议。为了避免LLMs生成连接的查询，JSP提示明确指示模型不要生成连接的查询，而是直接基于每轮的片段提供响应。</p>
</li>
<li><p><strong>引入免责声明</strong>：JSP通过将有害查询分解为无害片段，依次输入到多个轮次中来绕过LLMs的安全防护。然而，如果LLMs试图在响应中生成有害内容，防护机制仍可能介入。因此，提示强制LLMs在响应开始时生成免责声明，从而允许生成可能被阻止的内容。</p>
</li>
</ul>
<h3 id="JSP-分割策略"><a href="#JSP-分割策略" class="headerlink" title="JSP 分割策略"></a>JSP 分割策略</h3><p>作者将有害查询的内容分割处理为多个无害片段。具体流程分为三个阶段：</p>
<ul>
<li><p><strong>阶段一 - 重写查询</strong>：将有害查询统一重写为一种结构，以消除因句式不同所可能影响的破解效果。重写形式为：“如何实施 $+$ [有害行为]”，强调明确的有害请求和主观恶意意图。</p>
</li>
<li><p><strong>阶段二 - 句子级分割</strong>：在这一阶段，使用GPT-4工具自动识别出查询中的有害和敏感词汇。这些词汇的定位依据是安全原则。每次识别出的有害词汇都需要迭代处理，确保最终提取到的是具体的有害词汇。</p>
</li>
<li><p><strong>阶段三 - 词汇级分割</strong>：每个识别到的有害词汇再随机分割为无意义的字母片段，遵循两个标准：每个分割片段至少包含两个字母（对于三字母的单词则保持原样），且分割结果不得为与原词含义相关的新词。</p>
</li>
</ul>
<p>最终，处理后形成的无害片段在多轮交互中作为输入依次被输入到LLMs中。JSP策略利用LLMs在多轮交互中的记忆和推理功能，确保可以成功实现监狱破解。</p>
<h3 id="监狱破解过程示意图"><a href="#监狱破解过程示意图" class="headerlink" title="监狱破解过程示意图"></a>监狱破解过程示意图</h3><p><img src="/images/97a00d14482146ef83f588af28ce2c9d2832703863cab361d3de578afeb59d40.jpg"></p>
<p>该策略的实施依赖于精心设计的提示及分割策略，以确保能够有效突破现有的安全防护措施，诱导LLMs生成有害响应。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>该论文采用JSP策略对五种先进的LLM进行监狱逃逸（jailbreak）实验，涉及189个有害查询。实验分为几个部分，首先是实验设置，然后是对不同模型的监狱逃逸性能的报告，最后是对JSP策略在各种设置下的有效性分析。</p>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>数据集使用了Figstep（Gong et al., 2023）提出的有害问题数据集，包含500个问题，分为10个有害类别。由于成本原因，最终选取189个问题进行实验。参与实验的模型包括Gemini-1.5-Pro、GPT-4-turbo、GPT-4o、GPT-4o-mini和Llama-3.1-70B。通过其相应的API进行推理，并使用Llama-3.1-70B进行本地推理。</p>
<p>评价指标包括攻击成功率（ASR），具体分为每次尝试的攻击成功率（ASR-a）和按问题计算的攻击成功率（ASR-q）。ASR-a表示总尝试中成功攻击的百分比，而ASR-q表示成功越狱的问题百分比。为减少随机性，实验在每个模型上运行三次，并报告基于三次运行的平均ASR。</p>
<h3 id="监狱逃逸性能"><a href="#监狱逃逸性能" class="headerlink" title="监狱逃逸性能"></a>监狱逃逸性能</h3><p>首先对LLMs进行单轮交互的基线测试，这些测试使用原始的有害问题。结果表明，商业LLMs对有害单轮提问有着显著的防御能力，Gemini-1.5-Pro表现尤为突出，几乎阻止所有有害查询。采用JSP策略后的结果如下表所示：</p>
<p><img src="/images/ae7060caac9ca93772c10f1266fff7e01e6859ba334dbe42a0a3396528551659.jpg"> </p>
<p>在进行第二阶段的分裂（不带字词级分裂的JSP提示）时，所有模型的安全性显著下降，Llama-3.1-70B、GPT-4和GPT-4o-mini的ASR-q均超过90%。在第三阶段的分裂后，所有模型的攻击成功率再次提高，尤其是Llama-3.1-70B和GPT-4的ASR达到近100%。</p>
<h3 id="有害类别的监狱逃逸性能"><a href="#有害类别的监狱逃逸性能" class="headerlink" title="有害类别的监狱逃逸性能"></a>有害类别的监狱逃逸性能</h3><p>对于不同有害类别的逃逸性能，JSP策略在隐私侵犯、欺诈、恶意软件生成和非法活动方面表现出最高的攻击成功率。这些类别的表现从表中也能直观体现：</p>
<p><img src="/images/eacbfddfa907932e856b1a2a6cb7c3f489188b8e10d65e38fb59e1fc167f0ec7.jpg"> </p>
<h3 id="不同设置下的有效性分析"><a href="#不同设置下的有效性分析" class="headerlink" title="不同设置下的有效性分析"></a>不同设置下的有效性分析</h3><p>在多轮与单轮的实验设置对比中，结果显示多轮交互条件下的监狱逃逸性能优于单轮输入。在单轮设置中，由于所有切分的查询同时输入，往往会激活模型的防御机制，导致逃逸性能下降。然而，伪多轮设置提供了一种平衡的方法，可以改善单轮设置的监狱逃逸性能，特别是对GPT-4o-mini。</p>
<p>对于不同的切分策略，JSP的切分策略（将有害部分分隔为无害的部分）在多轮交互中优于逐字（word-by-word）和基于Tokenizer的切分策略。通过这种分裂，JSP能够保持对模型记忆与推理能力的低要求，特别是在Gemini-1.5-Pro上，这种策略有效地展示了JSP的优势。</p>
<p>在实施“伪装历史”的实验中，遇到模型在收到所有分段后但在用户输入“开始”之前生成拒绝响应的情况。通过调整响应，使用“开始”作为提示，稍微提高了跨所有模型的逃逸性能。</p>
<p>从以上实验结果中可以看出，JSP策略在多轮交互条件下，成功揭示了现有LLM防御中的弱点，为未来安全机制的发展提供了重要的参考依据。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了Jigsaw Puzzles (JSP)策略，这是一种简单且有效的多轮交互越狱大语言模型的方法。通过将有害问题拆分为多个词和字母片段，在每个回合输入时配以精心设计的提示，JSP成功在189个有害问题上实现了93.76%的平均攻击成功率，涵盖了五种最新的大语言模型。此外，JSP在对GPT-4的越狱中实现了行业领先的表现，超越了现有的越狱方法，并展现出对多种防御策略的强大抵抗能力。研究表明，当前的大语言模型在多轮交互中的安全防护存在漏洞，呼吁进一步开发更强大的防御机制以增强模型的安全性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/26/2410-11459/" data-id="cm2qbfyxn0009qrjlhqxgbcne" data-title="莫纳什大学提出多轮交互的Jigsaw Puzzles策略以破解大型语言模型的安全防护" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/10/26/2410-10414/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          新加坡国立大学提出的基于大型语言模型的内容审核守护模型的可靠性校准方法
        
      </div>
    </a>
  
  
    <a href="/2024/10/26/2410-12855/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">香港科技大学提出JAILJUDGE：一套综合性恶意指令评估基准与多智能体增强解释评估框架</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/26/2410-09804/">北京航空航天大学提出一种多目标黑箱优化框架BlackDAN用于有效的上下文劫持大型语言模型</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-09040/">加州大学圣克鲁斯分校提出了一种基于注意力操控的增强型大语言模型越狱攻击方法</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-10414/">新加坡国立大学提出的基于大型语言模型的内容审核守护模型的可靠性校准方法</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-11459/">莫纳什大学提出多轮交互的Jigsaw Puzzles策略以破解大型语言模型的安全防护</a>
          </li>
        
          <li>
            <a href="/2024/10/26/2410-12855/">香港科技大学提出JAILJUDGE：一套综合性恶意指令评估基准与多智能体增强解释评估框架</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Jun<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>